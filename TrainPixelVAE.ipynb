{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import utils\n",
    "import tensorboard_log_pixel\n",
    "\n",
    "import models\n",
    "\n",
    "import torchbearer as tb\n",
    "\n",
    "from tensorboard_log_pixel import ReconstructionsLogger, TensorBoardModelLogger, LatentSpaceReconLogger, RandomReconLogger\n",
    "from torchbearer import Trial\n",
    "from torchbearer.callbacks.tensor_board import TensorBoard\n",
    "from utils import AEDatasetWrapper\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled=False\n",
    "\n",
    "# Parameters:\n",
    "params = {'batch_size': 32,\n",
    "            'nEpoch': 50,\n",
    "            'imgSize': 64,\n",
    "            'zsize': 64,\n",
    "            'depth': 0,\n",
    "             'outcn': 0,\n",
    "            'lr': 1e-3,\n",
    "             'trainSize': 1500,\n",
    "             'testSize': 150}\n",
    "\n",
    "# Dataset construction\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # convert to tensor\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = AEDatasetWrapper(torchvision.datasets.CIFAR10('.', train=True, transform=transform))\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, num_workers=3)\n",
    "# testset = AEDatasetWrapper(torchvision.datasets.CIFAR10('.', train=False, transform=transform))\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=params['batch_size'], shuffle=False, num_workers=3)\n",
    "trainloader, testloader = utils.getloaders('imagenet_valid/', batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# construct the encoder, decoder and optimiser\n",
    "iSize = params['imgSize']\n",
    "\n",
    "vae = models.PixelVAE(iSize, params['zsize'], params['depth'], params['outcn'])\n",
    "optimizer = optim.Adam(vae.parameters(), lr=params['lr'])\n",
    "\n",
    "tb_comment = 'testing'\n",
    "tbl = TensorBoard(write_graph=True, comment=tb_comment)\n",
    "tbml = TensorBoardModelLogger(comment=tb_comment)\n",
    "rsl = ReconstructionsLogger(comment=tb_comment, output_shape=(3, iSize, iSize))\n",
    "rrsl = tensorboard_log_pixel.RandomPixReconLogger(comment=tb_comment, latent_dim=params['zsize'], output_shape=(3, iSize, iSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--------------------- OPTIMZER ---------------------\n",
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")\n",
       "\n",
       "-------------------- CRITERION ---------------------\n",
       "<function PixelVAE.loss_ce at 0x7ff011fcf158>\n",
       "\n",
       "--------------------- METRICS ----------------------\n",
       "['loss', 'recons_loss']\n",
       "\n",
       "-------------------- CALLBACKS ---------------------\n",
       "['torchbearer.callbacks.tensor_board.TensorBoard', 'tensorboard_log_pixel.ReconstructionsLogger', 'tensorboard_log_pixel.TensorBoardModelLogger', 'tensorboard_log_pixel.RandomPixReconLogger']\n",
       "\n",
       "---------------------- MODEL -----------------------\n",
       "PixelVAE(\n",
       "  (enc): ImEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Block(\n",
       "        (upchannels): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (seq): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Block(\n",
       "        (upchannels): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (seq): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Block(\n",
       "        (upchannels): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (seq): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Flatten()\n",
       "      (7): Linear(in_features=8192, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec): Lambda()\n",
       "  (pixcnn): CGated(\n",
       "    (conv1): Conv2d(3, 63, kernel_size=(1, 1), stride=(1, 1), groups=3)\n",
       "    (gated_layers): ModuleList(\n",
       "      (0): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "      (1): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "      (2): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "      (3): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "      (4): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "      (5): CMaskedConv2d(\n",
       "        (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "        (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "        (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Conv2d(63, 768, kernel_size=(1, 1), stride=(1, 1), groups=3)\n",
       "  )\n",
       ")\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = Trial(vae, optimizer, models.PixelVAE.loss_ce, metrics=['loss', models.sampled_recons_loss()], callbacks=[tbl, rsl, tbml, rrsl]).to(device)\n",
    "trial.with_generators(trainloader, val_generator=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/home/ar5g15/.local/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC1ENS_14SourceLocationERKSs')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PixelVAE(\n",
       "   (enc): ImEncoder(\n",
       "     (encoder): Sequential(\n",
       "       (0): Block(\n",
       "         (upchannels): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (seq): Sequential(\n",
       "           (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (1): ReLU()\n",
       "           (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (3): ReLU()\n",
       "           (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (5): ReLU()\n",
       "         )\n",
       "       )\n",
       "       (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "       (2): Block(\n",
       "         (upchannels): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (seq): Sequential(\n",
       "           (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (1): ReLU()\n",
       "           (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (3): ReLU()\n",
       "           (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (5): ReLU()\n",
       "         )\n",
       "       )\n",
       "       (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "       (4): Block(\n",
       "         (upchannels): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (seq): Sequential(\n",
       "           (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (1): ReLU()\n",
       "           (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (3): ReLU()\n",
       "           (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (5): ReLU()\n",
       "         )\n",
       "       )\n",
       "       (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "       (6): Flatten()\n",
       "       (7): Linear(in_features=8192, out_features=128, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (dec): Lambda()\n",
       "   (pixcnn): CGated(\n",
       "     (conv1): Conv2d(3, 63, kernel_size=(1, 1), stride=(1, 1), groups=3)\n",
       "     (gated_layers): ModuleList(\n",
       "       (0): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "       (1): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "       (2): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "       (3): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "       (4): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "       (5): CMaskedConv2d(\n",
       "         (vertical): Conv2d(63, 126, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "         (horizontal): Conv2d(63, 126, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "         (tohori): Conv2d(126, 126, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (tores): Conv2d(63, 63, kernel_size=(1, 1), stride=(1, 1), groups=3, bias=False)\n",
       "         (vhf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vhg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvf): Linear(in_features=64, out_features=258048, bias=True)\n",
       "         (vvg): Linear(in_features=64, out_features=258048, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (conv2): Conv2d(63, 768, kernel_size=(1, 1), stride=(1, 1), groups=3)\n",
       "   )\n",
       " ), Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp.initialize(vae, optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.limit_steps(trial, params['trainSize'], params['testSize'])\n",
    "trial.run(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
